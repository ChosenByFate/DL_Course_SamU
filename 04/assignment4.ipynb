{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChosenByFate/DL_Course_SamU/blob/main/04/assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anQwNbSYdMJa"
      },
      "source": [
        "# Лабораторная работа 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yud748QMdMJq"
      },
      "source": [
        "Tensorflow 2.x\n",
        "\n",
        "1) Подготовка данных\n",
        "\n",
        "2) Использование Keras Model API\n",
        "\n",
        "3) Использование Keras Sequential + Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6MvC2HWdMJr"
      },
      "source": [
        "https://www.tensorflow.org/tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOEdtBP7dMJt"
      },
      "source": [
        "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
        "\n",
        "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq6Gpar0dMJu"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17bM707bdMJy"
      },
      "source": [
        "# Подготовка данных\n",
        "Загрузите набор данных из предыдущей лабораторной работы. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr1oNieVdMJz",
        "outputId": "81a1a5b6-a614-45b9-bd8f-15e9f83886c1"
      },
      "source": [
        "def load_mnist(num_training=50000, num_validation=10000, num_test=10000):\n",
        "    \"\"\"\n",
        "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
        "    it for the two-layer neural net classifier. These are the same steps as\n",
        "    we used for the SVM, but condensed to a single function.\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
        "    mnist = tf.keras.datasets.mnist.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = mnist\n",
        "    X_train = np.asarray(X_train, dtype=np.float32)\n",
        "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
        "    X_test = np.asarray(X_test, dtype=np.float32)\n",
        "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
        "\n",
        "    # Subsample the data\n",
        "    mask = range(num_training, num_training + num_validation)\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = range(num_training)\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = range(num_test)\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Normalize the data: subtract the mean pixel and divide by std\n",
        "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
        "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
        "    X_train = (X_train - mean_pixel) / std_pixel\n",
        "    X_val = (X_val - mean_pixel) / std_pixel\n",
        "    X_test = (X_test - mean_pixel) / std_pixel\n",
        "\n",
        "    X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1], X_train.shape[2]))\n",
        "    X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1], X_val.shape[2]))\n",
        "    X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# If there are errors with SSL downloading involving self-signed certificates,\n",
        "# it may be that your Python version was recently installed on the current machine.\n",
        "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
        "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
        "#   ...replacing paths as necessary.\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "NHW = (0, 1, 2)\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train data shape:  (50000, 1, 28, 28)\n",
            "Train labels shape:  (50000,) int32\n",
            "Validation data shape:  (10000, 1, 28, 28)\n",
            "Validation labels shape:  (10000,)\n",
            "Test data shape:  (10000, 1, 28, 28)\n",
            "Test labels shape:  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKxlUzjNdMJ1"
      },
      "source": [
        "class Dataset(object):\n",
        "    def __init__(self, X, y, batch_size, shuffle=False):\n",
        "        \"\"\"\n",
        "        Construct a Dataset object to iterate over data X and labels y\n",
        "        \n",
        "        Inputs:\n",
        "        - X: Numpy array of data, of any shape\n",
        "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
        "        - batch_size: Integer giving number of elements per minibatch\n",
        "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
        "        \"\"\"\n",
        "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
        "        self.X, self.y = X, y\n",
        "        self.batch_size, self.shuffle = batch_size, shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        N, B = self.X.shape[0], self.batch_size\n",
        "        idxs = np.arange(N)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(idxs)\n",
        "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
        "\n",
        "\n",
        "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
        "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
        "test_dset = Dataset(X_test, y_test, batch_size=64)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfSES3Y1dMJ2",
        "outputId": "5c071b11-e3df-43a6-e386-3979a462f102"
      },
      "source": [
        "# We can iterate through a dataset like this:\n",
        "for t, (x, y) in enumerate(train_dset):\n",
        "    print(t, x.shape, y.shape)\n",
        "    if t > 5: break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 (64, 1, 28, 28) (64,)\n",
            "1 (64, 1, 28, 28) (64,)\n",
            "2 (64, 1, 28, 28) (64,)\n",
            "3 (64, 1, 28, 28) (64,)\n",
            "4 (64, 1, 28, 28) (64,)\n",
            "5 (64, 1, 28, 28) (64,)\n",
            "6 (64, 1, 28, 28) (64,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQbFSxhMdMJ2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rxOfTNxdMJ3"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjJVqeU_dMJ3"
      },
      "source": [
        "#  Keras Model Subclassing API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZl4ilzkdMJ3"
      },
      "source": [
        "\n",
        "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
        "\n",
        "1) Определить новый класс, который является наследником tf.keras.Model.\n",
        "\n",
        "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
        "\n",
        "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
        "\n",
        "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети. \n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcEtW30cmQMJ"
      },
      "source": [
        "device = \"GPU\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_WDhmUWdMJ4",
        "outputId": "a6161b14-8c9d-403e-ac86-ff1dd850400e"
      },
      "source": [
        "class TwoLayerFC(tf.keras.Model):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(TwoLayerFC, self).__init__()        \n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
        "                                   kernel_initializer=initializer)\n",
        "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                                   kernel_initializer=initializer)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "    \n",
        "    def call(self, x, training=False):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def test_TwoLayerFC():\n",
        "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
        "    input_size, hidden_size, num_classes = 50, 42, 10\n",
        "    x = tf.zeros((64, input_size))\n",
        "    model = TwoLayerFC(hidden_size, num_classes)\n",
        "    with tf.device(device):\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "        \n",
        "test_TwoLayerFC()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZnhOXWxdMJ4"
      },
      "source": [
        "Реализуйте трехслойную CNN для вашей задачи классификации. \n",
        "\n",
        "Архитектура сети:\n",
        "    \n",
        "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
        "2. Функция активации ReLU \n",
        "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
        "4. Функция активации ReLU \n",
        "5. Полносвязный слой \n",
        "6. Функция активации Softmax \n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgVoaVzqdMJ5"
      },
      "source": [
        "class ThreeLayerConvNet(tf.keras.Model):\n",
        "    def __init__(self, channel_1, channel_2, num_classes):\n",
        "        super(ThreeLayerConvNet, self).__init__()\n",
        "        ########################################################################\n",
        "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
        "        # should instantiate layer objects to be used in the forward pass.     #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "        self.conv1 = tf.keras.layers.Conv2D(channel_1, kernel_size=(5,5), padding='same', activation='relu', kernel_initializer=initializer)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(channel_2, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=initializer)\n",
        "        self.fc3 = tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=initializer)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        pass\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                           END OF YOUR CODE                           #\n",
        "        ########################################################################\n",
        "        \n",
        "    def call(self, x, training=False):\n",
        "        scores = None\n",
        "        ########################################################################\n",
        "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
        "        # should use the layer objects defined in the __init__ method.         #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "        pass\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                           END OF YOUR CODE                           #\n",
        "        ########################################################################        \n",
        "        return scores"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcERNuL3dMJ6",
        "outputId": "062199d3-b5b0-4cb7-b15c-3e01c9170ad8"
      },
      "source": [
        "def test_ThreeLayerConvNet():    \n",
        "    channel_1, channel_2, num_classes = 12, 8, 10\n",
        "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
        "    with tf.device(device):\n",
        "        x = tf.zeros((64, 3, 32, 32))\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "\n",
        "test_ThreeLayerConvNet()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNN7Ru9XdMJ6"
      },
      "source": [
        "Пример реализации процесса обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O17n1jVjdMJ6"
      },
      "source": [
        "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
        "    \"\"\"\n",
        "    Simple training loop for use with models defined using tf.keras. It trains\n",
        "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
        "    accuracy on the CIFAR-10 validation set.\n",
        "    \n",
        "    Inputs:\n",
        "    - model_init_fn: A function that takes no parameters; when called it\n",
        "      constructs the model we want to train: model = model_init_fn()\n",
        "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
        "      constructs the Optimizer object we will use to optimize the model:\n",
        "      optimizer = optimizer_init_fn()\n",
        "    - num_epochs: The number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints progress during training\n",
        "    \"\"\"    \n",
        "    with tf.device(device):\n",
        "\n",
        "        \n",
        "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "        \n",
        "        model = model_init_fn()\n",
        "        optimizer = optimizer_init_fn()\n",
        "        \n",
        "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "    \n",
        "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
        "        \n",
        "        t = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            \n",
        "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
        "            train_loss.reset_states()\n",
        "            train_accuracy.reset_states()\n",
        "            \n",
        "            for x_np, y_np in train_dset:\n",
        "                with tf.GradientTape() as tape:\n",
        "                    \n",
        "                    # Use the model function to build the forward pass.\n",
        "                    scores = model(x_np, training=is_training)\n",
        "                    loss = loss_fn(y_np, scores)\n",
        "      \n",
        "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "                    \n",
        "                    # Update the metrics\n",
        "                    train_loss.update_state(loss)\n",
        "                    train_accuracy.update_state(y_np, scores)\n",
        "                    \n",
        "                    if t % print_every == 0:\n",
        "                        val_loss.reset_states()\n",
        "                        val_accuracy.reset_states()\n",
        "                        for test_x, test_y in val_dset:\n",
        "                            # During validation at end of epoch, training set to False\n",
        "                            prediction = model(test_x, training=False)\n",
        "                            t_loss = loss_fn(test_y, prediction)\n",
        "\n",
        "                            val_loss.update_state(t_loss)\n",
        "                            val_accuracy.update_state(test_y, prediction)\n",
        "                        \n",
        "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
        "                        print (template.format(t, epoch+1,\n",
        "                                             train_loss.result(),\n",
        "                                             train_accuracy.result()*100,\n",
        "                                             val_loss.result(),\n",
        "                                             val_accuracy.result()*100))\n",
        "                    t += 1\n",
        "        test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "        for x_np, y_np in test_dset:\n",
        "          prediction = model(x_np, training=False)\n",
        "          test_accuracy.update_state(y_np, prediction)\n",
        "        print(\"Test accuracy: {}\".format(test_accuracy.result()*100))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KgFQ8WhdMJ7",
        "outputId": "cef0525a-eadd-47d6-821f-3881789e0c76"
      },
      "source": [
        "hidden_size, num_classes = 4000, 10\n",
        "learning_rate = 1e-2\n",
        "print_every = 100\n",
        "\n",
        "def model_init_fn():\n",
        "    return TwoLayerFC(hidden_size, num_classes)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.96191143989563, Accuracy: 18.75, Val Loss: 2.659280776977539, Val Accuracy: 21.969999313354492\n",
            "Iteration 100, Epoch 1, Loss: 0.6305063962936401, Accuracy: 80.81682586669922, Val Loss: 0.40173834562301636, Val Accuracy: 87.75\n",
            "Iteration 200, Epoch 1, Loss: 0.5006923079490662, Accuracy: 84.7403564453125, Val Loss: 0.3152967393398285, Val Accuracy: 90.61000061035156\n",
            "Iteration 300, Epoch 1, Loss: 0.4420437812805176, Accuracy: 86.61752319335938, Val Loss: 0.28252923488616943, Val Accuracy: 91.13999938964844\n",
            "Iteration 400, Epoch 1, Loss: 0.4002740979194641, Accuracy: 87.98316955566406, Val Loss: 0.25382137298583984, Val Accuracy: 92.5\n",
            "Iteration 500, Epoch 1, Loss: 0.3771345913410187, Accuracy: 88.70384216308594, Val Loss: 0.2375023514032364, Val Accuracy: 92.98999786376953\n",
            "Iteration 600, Epoch 1, Loss: 0.35425707697868347, Accuracy: 89.37967681884766, Val Loss: 0.22392897307872772, Val Accuracy: 93.56999969482422\n",
            "Iteration 700, Epoch 1, Loss: 0.3381066620349884, Accuracy: 89.90281677246094, Val Loss: 0.21392329037189484, Val Accuracy: 93.69999694824219\n",
            "Test accuracy: 93.33999633789062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfQasy8XdMJ9"
      },
      "source": [
        "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 . \n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
        "\n",
        "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzeiZ_MRdMJ_",
        "outputId": "c9f3475a-4a1b-4f98-c4df-b96ee6ab7e01"
      },
      "source": [
        "learning_rate = 3e-3\n",
        "channel_1, channel_2, num_classes = 32, 16, 10\n",
        "\n",
        "def model_init_fn():\n",
        "    model = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    model = ThreeLayerConvNet(channel_1=channel_1, channel_2=channel_2, num_classes=num_classes)\n",
        "    pass\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    optimizer = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "    pass\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return optimizer\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.3089466094970703, Accuracy: 7.8125, Val Loss: 2.343623161315918, Val Accuracy: 9.710000038146973\n",
            "Iteration 100, Epoch 1, Loss: 1.408502221107483, Accuracy: 55.863243103027344, Val Loss: 0.5576921105384827, Val Accuracy: 81.95000457763672\n",
            "Iteration 200, Epoch 1, Loss: 0.9478008151054382, Accuracy: 70.70895385742188, Val Loss: 0.40607452392578125, Val Accuracy: 87.69000244140625\n",
            "Iteration 300, Epoch 1, Loss: 0.7525426745414734, Accuracy: 76.9362564086914, Val Loss: 0.26948806643486023, Val Accuracy: 91.82999420166016\n",
            "Iteration 400, Epoch 1, Loss: 0.6342098116874695, Accuracy: 80.564208984375, Val Loss: 0.24159488081932068, Val Accuracy: 92.5999984741211\n",
            "Iteration 500, Epoch 1, Loss: 0.5629077553749084, Accuracy: 82.9091796875, Val Loss: 0.2175150066614151, Val Accuracy: 93.33000183105469\n",
            "Iteration 600, Epoch 1, Loss: 0.5084498524665833, Accuracy: 84.5673828125, Val Loss: 0.2162906676530838, Val Accuracy: 93.30000305175781\n",
            "Iteration 700, Epoch 1, Loss: 0.46723875403404236, Accuracy: 85.88177490234375, Val Loss: 0.18369591236114502, Val Accuracy: 94.31999969482422\n",
            "Test accuracy: 94.91000366210938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qve2izaidMKA"
      },
      "source": [
        "# Использование Keras Sequential API для реализации последовательных моделей.\n",
        "\n",
        "Пример для полносвязной сети:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-mf0IJXdMKB",
        "outputId": "6291d096-fcca-4420-f215-19c5368a7f23"
      },
      "source": [
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    input_shape = (28, 28, 1)\n",
        "    hidden_layer_size, num_classes = 4000, 10\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    layers = [\n",
        "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
        "                              kernel_initializer=initializer),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax', \n",
        "                              kernel_initializer=initializer),\n",
        "    ]\n",
        "    model = tf.keras.Sequential(layers)\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate) \n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.0788803100585938, Accuracy: 9.375, Val Loss: 2.77116322517395, Val Accuracy: 10.260000228881836\n",
            "Iteration 100, Epoch 1, Loss: 0.6452388167381287, Accuracy: 79.8731460571289, Val Loss: 0.41270115971565247, Val Accuracy: 87.9800033569336\n",
            "Iteration 200, Epoch 1, Loss: 0.5119789242744446, Accuracy: 84.68594360351562, Val Loss: 0.3251451253890991, Val Accuracy: 90.94999694824219\n",
            "Iteration 300, Epoch 1, Loss: 0.45307278633117676, Accuracy: 86.47737121582031, Val Loss: 0.2875993549823761, Val Accuracy: 91.44999694824219\n",
            "Iteration 400, Epoch 1, Loss: 0.4085933566093445, Accuracy: 87.86627197265625, Val Loss: 0.2595386505126953, Val Accuracy: 92.41999816894531\n",
            "Iteration 500, Epoch 1, Loss: 0.38435375690460205, Accuracy: 88.5978012084961, Val Loss: 0.2422180473804474, Val Accuracy: 93.16999816894531\n",
            "Iteration 600, Epoch 1, Loss: 0.36104831099510193, Accuracy: 89.31208038330078, Val Loss: 0.23103424906730652, Val Accuracy: 93.66000366210938\n",
            "Iteration 700, Epoch 1, Loss: 0.3437128961086273, Accuracy: 89.84931945800781, Val Loss: 0.21754032373428345, Val Accuracy: 93.80000305175781\n",
            "Test accuracy: 93.31999969482422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIBG9UWNdMKB"
      },
      "source": [
        "Альтернативный менее гибкий способ обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGQzZSc2dMKC",
        "outputId": "a2261e0f-d11b-482d-f77e-a5b18cf54b84"
      },
      "source": [
        "model = model_init_fn()\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input Tensor(\"flatten_5_input:0\", shape=(None, 28, 28, 1), dtype=float32), but it was called on an input with incompatible shape (None, 1, 28, 28).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input Tensor(\"flatten_5_input:0\", shape=(None, 28, 28, 1), dtype=float32), but it was called on an input with incompatible shape (None, 1, 28, 28).\n",
            "771/782 [============================>.] - ETA: 0s - loss: 0.3406 - sparse_categorical_accuracy: 0.8993WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input Tensor(\"flatten_5_input:0\", shape=(None, 28, 28, 1), dtype=float32), but it was called on an input with incompatible shape (None, 1, 28, 28).\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.3394 - sparse_categorical_accuracy: 0.8996 - val_loss: 0.2099 - val_sparse_categorical_accuracy: 0.9412\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2201 - sparse_categorical_accuracy: 0.9366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2201450616121292, 0.9366000294685364]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g02fToVMdMKC"
      },
      "source": [
        "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oXtoXeedMKD",
        "outputId": "8885f3c6-eaf8-4b0b-bca3-e54b62331e75"
      },
      "source": [
        "def model_init_fn():\n",
        "    model = None\n",
        "    ############################################################################\n",
        "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    input_shape = (28, 28, 1)\n",
        "    channel_1, channel_2, num_classes = 12, 8, 10\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "\n",
        "    layers = [\n",
        "        tf.keras.layers.Conv2D(channel_1, kernel_size=(5,5), padding='same', activation='relu', kernel_initializer=initializer),\n",
        "        tf.keras.layers.Conv2D(channel_2, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=initializer),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=initializer),\n",
        "    ]\n",
        "    model = tf.keras.Sequential(layers)\n",
        "    pass\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                            END OF YOUR CODE                              #\n",
        "    ############################################################################\n",
        "    return model\n",
        "\n",
        "learning_rate = 5e-4\n",
        "def optimizer_init_fn():\n",
        "    optimizer = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True) \n",
        "    pass\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return optimizer\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.3700952529907227, Accuracy: 4.6875, Val Loss: 2.3460118770599365, Val Accuracy: 11.010000228881836\n",
            "Iteration 100, Epoch 1, Loss: 2.2696645259857178, Accuracy: 16.475866317749023, Val Loss: 2.210325241088867, Val Accuracy: 22.75\n",
            "Iteration 200, Epoch 1, Loss: 2.196300506591797, Accuracy: 22.916667938232422, Val Loss: 2.0295541286468506, Val Accuracy: 37.709999084472656\n",
            "Iteration 300, Epoch 1, Loss: 2.1015801429748535, Accuracy: 28.929609298706055, Val Loss: 1.7250677347183228, Val Accuracy: 49.32999801635742\n",
            "Iteration 400, Epoch 1, Loss: 1.9637075662612915, Accuracy: 34.86595916748047, Val Loss: 1.3170944452285767, Val Accuracy: 59.70000076293945\n",
            "Iteration 500, Epoch 1, Loss: 1.8179776668548584, Accuracy: 39.85466766357422, Val Loss: 0.9881656765937805, Val Accuracy: 69.22000122070312\n",
            "Iteration 600, Epoch 1, Loss: 1.6711903810501099, Accuracy: 44.969322204589844, Val Loss: 0.7792988419532776, Val Accuracy: 76.95000457763672\n",
            "Iteration 700, Epoch 1, Loss: 1.5446120500564575, Accuracy: 49.373661041259766, Val Loss: 0.649302065372467, Val Accuracy: 80.4000015258789\n",
            "Test accuracy: 81.84000396728516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn2SBv_DdMKD",
        "outputId": "40054b24-9cd1-485f-fa62-ee7172b2ec23"
      },
      "source": [
        "model = model_init_fn()\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 3ms/step - loss: 0.7002 - sparse_categorical_accuracy: 0.7895 - val_loss: 0.3051 - val_sparse_categorical_accuracy: 0.9105\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3093 - sparse_categorical_accuracy: 0.9109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30934759974479675, 0.9108999967575073]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7byY4kxRdMKE"
      },
      "source": [
        "# Использование Keras Functional API\n",
        "\n",
        "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры. \n",
        "\n",
        "Ниже представлен пример для полносвязной сети. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GOmQv8gdMKE",
        "outputId": "4f2ba83c-d01b-4d8f-b9b7-dccda576dd62"
      },
      "source": [
        "def two_layer_fc_functional(input_shape, hidden_size, num_classes):  \n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
        "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
        "                                 kernel_initializer=initializer)(flattened_inputs)\n",
        "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                             kernel_initializer=initializer)(fc1_output)\n",
        "\n",
        "    # Instantiate the model given inputs and outputs.\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
        "    return model\n",
        "\n",
        "def test_two_layer_fc_functional():\n",
        "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
        "    input_size, hidden_size, num_classes = 50, 42, 10\n",
        "    input_shape = (50,)\n",
        "    \n",
        "    x = tf.zeros((64, input_size))\n",
        "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
        "    \n",
        "    with tf.device(device):\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "        \n",
        "test_two_layer_fc_functional()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WthIsAXfdMKF",
        "outputId": "efbcd826-8bb5-464a-f3dc-c783570dcb52"
      },
      "source": [
        "input_shape = (28, 28, 1)\n",
        "hidden_size, num_classes = 4000, 10\n",
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.2264785766601562, Accuracy: 7.8125, Val Loss: 2.9507534503936768, Val Accuracy: 18.420000076293945\n",
            "Iteration 100, Epoch 1, Loss: 0.651204526424408, Accuracy: 80.5538330078125, Val Loss: 0.40293797850608826, Val Accuracy: 87.84000396728516\n",
            "Iteration 200, Epoch 1, Loss: 0.5129328966140747, Accuracy: 84.87251281738281, Val Loss: 0.3190971612930298, Val Accuracy: 90.55000305175781\n",
            "Iteration 300, Epoch 1, Loss: 0.4534941017627716, Accuracy: 86.61752319335938, Val Loss: 0.2998960018157959, Val Accuracy: 90.6500015258789\n",
            "Iteration 400, Epoch 1, Loss: 0.40891700983047485, Accuracy: 87.9403076171875, Val Loss: 0.2581421434879303, Val Accuracy: 92.36000061035156\n",
            "Iteration 500, Epoch 1, Loss: 0.3843814730644226, Accuracy: 88.65393829345703, Val Loss: 0.2416689395904541, Val Accuracy: 92.88999938964844\n",
            "Iteration 600, Epoch 1, Loss: 0.36111631989479065, Accuracy: 89.3328857421875, Val Loss: 0.23612944781780243, Val Accuracy: 93.3499984741211\n",
            "Iteration 700, Epoch 1, Loss: 0.34404754638671875, Accuracy: 89.85823822021484, Val Loss: 0.21573512256145477, Val Accuracy: 93.80999755859375\n",
            "Test accuracy: 93.29000091552734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Y_lvHsdMKF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLk0YfrfdMKF"
      },
      "source": [
        "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут). \n",
        "\n",
        "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESFcFaKHdMKG",
        "outputId": "be2ca5a8-364b-44b5-93b1-e2863e87bc5d"
      },
      "source": [
        "class CustomConvNet(tf.keras.Model):\n",
        "    def __init__(self, channel_1, channel_2, channel_3, channel_4, num_classes=10):\n",
        "        super(CustomConvNet, self).__init__()\n",
        "        ############################################################################\n",
        "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
        "        ############################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "        self.conv1 = tf.keras.layers.Conv2D(channel_1, kernel_size=(7,7), padding='same', activation='relu', kernel_initializer=initializer)\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(channel_2, kernel_size=(5,5), padding='same', activation='relu', kernel_initializer=initializer)\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(channel_3, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=initializer)\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv4 = tf.keras.layers.Conv2D(channel_4, kernel_size=(3,3), padding='same', activation='relu', kernel_initializer=initializer)\n",
        "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
        "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=initializer)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        pass\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                            END OF YOUR CODE                              #\n",
        "        ############################################################################\n",
        "    \n",
        "    def call(self, input_tensor, training=False):\n",
        "        ############################################################################\n",
        "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
        "        ############################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.bn1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        pass\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                            END OF YOUR CODE                              #\n",
        "        ############################################################################\n",
        "        return x\n",
        "\n",
        "\n",
        "print_every = 700\n",
        "num_epochs = 10\n",
        "\n",
        "# channel_1, channel_2, channel_3, channel_4 = 20, 16, 12, 10\n",
        "# channel_1, channel_2, channel_3, channel_4 = 20, 18, 16, 14\n",
        "# channel_1, channel_2, channel_3, channel_4 = 40, 34, 28, 24 # 98.4\n",
        "channel_1, channel_2, channel_3, channel_4 = 100, 80, 60, 40 #98.73\n",
        "# channel_1, channel_2, channel_3, channel_4 = 200, 140, 100, 40\n",
        "\n",
        "# model = CustomConvNet(channel_1, channel_2, channel_3)\n",
        "\n",
        "def model_init_fn():\n",
        "    return CustomConvNet(channel_1, channel_2, channel_3, channel_4)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    learning_rate = 1e-3\n",
        "    return tf.keras.optimizers.Adam(learning_rate, epsilon=1e-08) \n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.727301597595215, Accuracy: 18.75, Val Loss: 2.2908267974853516, Val Accuracy: 14.329999923706055\n",
            "Iteration 700, Epoch 1, Loss: 0.1598145067691803, Accuracy: 95.07845306396484, Val Loss: 0.08257576078176498, Val Accuracy: 97.65999603271484\n",
            "Iteration 1400, Epoch 2, Loss: 0.06215738132596016, Accuracy: 98.07148742675781, Val Loss: 0.070359967648983, Val Accuracy: 97.90999603271484\n",
            "Iteration 2100, Epoch 3, Loss: 0.04115518182516098, Accuracy: 98.66154479980469, Val Loss: 0.060202423483133316, Val Accuracy: 98.25999450683594\n",
            "Iteration 2800, Epoch 4, Loss: 0.035483185201883316, Accuracy: 98.8804931640625, Val Loss: 0.06331119686365128, Val Accuracy: 98.22000122070312\n",
            "Iteration 3500, Epoch 5, Loss: 0.03611747547984123, Accuracy: 98.7684326171875, Val Loss: 0.07043301314115524, Val Accuracy: 97.97999572753906\n",
            "Iteration 4200, Epoch 6, Loss: 0.02310101129114628, Accuracy: 99.23754119873047, Val Loss: 0.053132422268390656, Val Accuracy: 98.5999984741211\n",
            "Iteration 4900, Epoch 7, Loss: 0.02517286315560341, Accuracy: 99.17015075683594, Val Loss: 0.07074249535799026, Val Accuracy: 98.18999481201172\n",
            "Iteration 5600, Epoch 8, Loss: 0.024501308798789978, Accuracy: 99.11417388916016, Val Loss: 0.06642412394285202, Val Accuracy: 98.41999816894531\n",
            "Iteration 6300, Epoch 9, Loss: 0.02214541658759117, Accuracy: 99.27083587646484, Val Loss: 0.07092887908220291, Val Accuracy: 98.29000091552734\n",
            "Iteration 7000, Epoch 9, Loss: 0.018365982919931412, Accuracy: 99.40855407714844, Val Loss: 0.06946271657943726, Val Accuracy: 98.30999755859375\n",
            "Iteration 7700, Epoch 10, Loss: 0.015731343999505043, Accuracy: 99.46974182128906, Val Loss: 0.0709836557507515, Val Accuracy: 98.55999755859375\n",
            "Test accuracy: 98.72000122070312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kgbz-SsdMKG"
      },
      "source": [
        "Опишите все эксперименты, результаты. Сделайте выводы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af57twqMDlKk"
      },
      "source": [
        "<p>Стандартная архтектура с 3 слоями даёт точность около 97.5% на тестовой выборке.</p>\r\n",
        "<p>Добавил ещё несколько свёрточных слоёв, BN после каждого из них. Оптимизатор - Adam, скорость обучения 1e-3 - оптимальная, при изменении точность проседает.</p>\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "<p><b>В итоге точность.</b></p>\r\n",
        "<p>На <i>тренеровочной</i> выборке: <i>99.47%</i>.</p>\r\n",
        "<p>На <i>валидационной</i> выборке: <i>98.56%</i>.</p>\r\n",
        "<p>На <i>тестовой</i> выборке: <i>98.72%</i>.</p>\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Неплохая точность. Точность в 97% на тестовой выборке достигается очень просто. Усложняя сеть, можно добиться лучшего. Но за эти 1.5-2% плата - увеличение времени обучения более чем в 2 раза."
      ]
    }
  ]
}